---
phase: 15-parameter-inspection
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - playground/utils/parameter_inspector.py
  - playground/utils/__init__.py
  - playground/quantization.py
autonomous: true

must_haves:
  truths:
    - "Extraction functions return scale, zero-point, weight shape, and dtype for any ONNX QDQ layer"
    - "Per-channel scales are summarized as min/max/mean, not raw arrays"
    - "Layers without quantization parameters return None gracefully"
    - "Layer dropdown shows indicator of which layers have quantization parameters"
    - "Whole-model layer ranges (min-to-max weight values) can be computed for all weight-bearing layers"
  artifacts:
    - path: "playground/utils/parameter_inspector.py"
      provides: "ONNX quantization parameter extraction and weight tensor access"
      exports: ["extract_layer_params", "extract_weight_tensors", "compute_all_layer_ranges", "dequantize_weights"]
    - path: "playground/utils/__init__.py"
      provides: "Updated exports including parameter_inspector functions"
      contains: "parameter_inspector"
    - path: "playground/quantization.py"
      provides: "Enhanced layer dropdown with quantization param indicators"
      contains: "has_params"
  key_links:
    - from: "playground/utils/parameter_inspector.py"
      to: "onnx.numpy_helper.to_array"
      via: "initializer extraction"
      pattern: "nph\\.to_array|numpy_helper"
    - from: "playground/utils/parameter_inspector.py"
      to: "onnx graph traversal"
      via: "QuantizeLinear/DequantizeLinear node matching"
      pattern: "QuantizeLinear|DequantizeLinear"
    - from: "playground/quantization.py"
      to: "playground/utils/parameter_inspector.py"
      via: "import and call in dropdown cell"
      pattern: "from playground\\.utils import"
---

<objective>
Create the parameter extraction utilities for ONNX QDQ models and enhance the existing layer dropdown with quantization parameter indicators.

Purpose: This is the data layer for Phase 15. All visualization cells (heatmap, table, histograms) depend on these extraction functions. The enhanced dropdown lets users immediately see which layers have quantization parameters worth inspecting.

Output: `playground/utils/parameter_inspector.py` with extraction functions, updated `__init__.py` exports, and enhanced layer dropdown in the notebook.
</objective>

<execution_context>
@/home/impactaky/shelffiles/config/claude/get-shit-done/workflows/execute-plan.md
@/home/impactaky/shelffiles/config/claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/15-parameter-inspection/parameter-inspection-CONTEXT.md
@.planning/phases/15-parameter-inspection/15-RESEARCH.md
@.planning/phases/14-notebook-foundation/14-02-SUMMARY.md

# Key source files to understand existing patterns
@playground/utils/layer_inspector.py
@playground/utils/model_loader.py
@playground/utils/__init__.py
@playground/quantization.py
@scripts/extract_operations.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create parameter_inspector.py with ONNX extraction functions</name>
  <files>playground/utils/parameter_inspector.py, playground/utils/__init__.py</files>
  <action>
Create `playground/utils/parameter_inspector.py` with these functions:

1. **`extract_layer_params(model, layer_name)`** - Extract quantization parameters for a specific ONNX layer.
   - Build initializer lookup dict: `{init.name: nph.to_array(init) for init in model.graph.initializer}`
   - Find QuantizeLinear/DequantizeLinear nodes where `layer_name` appears in the node name or in node inputs/outputs.
   - For matching nodes, extract scale (input[1]) and zero_point (input[2]) from initializers.
   - Also find associated weight initializers by matching naming patterns (the quantized weight tensor name often contains the layer name prefix, e.g., `const_fold_opt__139_quantized`).
   - Return dict with keys: `scale` (numpy array), `zero_point` (numpy array), `weight_shape` (tuple or None), `weight_dtype` (str like "int8"/"uint8"/"float32" or None), `node_type` (str), `is_per_channel` (bool based on `scale.ndim > 0`).
   - Return None if no quantization parameters found for this layer.
   - Handle per-channel scales (1D array) vs per-tensor (scalar) -- detect via `scale.ndim`.

2. **`extract_weight_tensors(fp32_model, int8_model, layer_name, uint8_model=None)`** - Extract weight tensors from multiple model variants for comparison.
   - For each model (if not None), search `graph.initializer` for tensors whose name contains `layer_name` and whose dtype is a weight type (float32, int8, uint8).
   - For INT8/UINT8 weights, dequantize using the formula: `(raw.astype(np.float32) - zero_point) * scale`. Find the matching scale/zero_point from the same model's QuantizeLinear/DequantizeLinear nodes.
   - Return dict with keys: `fp32` (numpy array or None), `int8_dequantized` (numpy array or None), `uint8_dequantized` (numpy array or None), `int8_raw` (numpy array or None), `uint8_raw` (numpy array or None).
   - Return dict with all None values if no weights found.

3. **`compute_all_layer_ranges(fp32_model, int8_model)`** - Compute weight value ranges for all layers in both models.
   - Iterate over all initializers in each model.
   - For fp32_model: collect initializers that are float32 weight tensors (ndim >= 2, shape suggests conv/fc weights not biases).
   - For int8_model: collect corresponding quantized weight initializers and dequantize them.
   - Return list of dicts: `[{name, fp32_min, fp32_max, fp32_range, int8_min, int8_max, int8_range}, ...]`.
   - Filter to only layers that have weights in BOTH models for meaningful comparison.
   - Sort by layer name for consistent ordering.

4. **`get_layers_with_params(model)`** - Return set of layer names that have QuantizeLinear/DequantizeLinear nodes.
   - Simple traversal: collect all node names where `node.op_type in ["QuantizeLinear", "DequantizeLinear"]`.
   - Also collect parent layer names by parsing the naming convention (e.g., `const_fold_opt__139_DequantizeLinear` -> extract prefix patterns).
   - Return a set of strings.

Use `onnx.numpy_helper` (imported as `nph`) for tensor extraction -- do NOT hand-roll raw_data parsing.
Use `numpy` for all array operations and statistics.
Handle edge cases: missing initializers, empty scale arrays, layers with no associated Q/DQ nodes.
Follow the existing code style from `layer_inspector.py` (type hints, docstrings, explicit returns).

After creating the module, update `playground/utils/__init__.py` to export:
- `extract_layer_params`
- `extract_weight_tensors`
- `compute_all_layer_ranges`
- `get_layers_with_params`
  </action>
  <verify>
Run `python -c "from playground.utils import extract_layer_params, extract_weight_tensors, compute_all_layer_ranges, get_layers_with_params; print('All imports OK')"` from project root.
Run `ruff check playground/utils/parameter_inspector.py` to verify no lint errors.
  </verify>
  <done>
parameter_inspector.py exists with 4 exported functions. All imports succeed. No lint errors. Functions handle None models and missing parameters gracefully (return None or empty structures, never raise on missing data).
  </done>
</task>

<task type="auto">
  <name>Task 2: Enhance layer dropdown with quantization parameter indicators</name>
  <files>playground/quantization.py</files>
  <action>
Modify the existing `playground/quantization.py` to enhance the layer dropdown with indicators showing which layers have quantization parameters.

Changes to existing cells:

1. **Update import cell**: Add `get_layers_with_params` to the imports from `playground.utils`.

2. **Update layer extraction cell** (the cell that calls `get_all_layer_names`): After extracting `layer_names`, also call `get_layers_with_params(models["onnx_int8"])` (if onnx_int8 is available) to get the set of layers with Q/DQ parameters. Store this as `layers_with_params`.

3. **Update dropdown cell**: Instead of plain `layer_names` as options, create annotated options. For each layer name, append a marker like " [Q]" if the layer is in `layers_with_params`, so users can visually identify which layers have quantization parameters. The dropdown `options` should be a dict mapping display strings to raw layer names, e.g., `{"Conv_0 [Q]": "Conv_0", "Relu_0": "Relu_0"}`. This way `layer_selector.value` still returns the clean layer name for downstream use.

Important: Keep all existing cells intact. The layer_info display cell and all other existing cells must continue to work. The dropdown enhancement is additive -- it just adds visual indicators.

Do NOT use plt.show() anywhere -- Marimo renders returned figure/axes objects.
Do NOT add any visualization cells yet (that is Plan 02).
  </action>
  <verify>
Run `ruff check playground/quantization.py` to verify no lint errors.
Visually inspect that the dropdown cell creates a dict-based options mapping with "[Q]" indicators.
Verify that `layer_selector.value` still returns clean layer names (not the display strings with "[Q]").
  </verify>
  <done>
Layer dropdown shows "[Q]" indicator next to layers that have QuantizeLinear/DequantizeLinear nodes. The indicator is purely visual -- `layer_selector.value` returns the raw layer name. All existing cells remain functional.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from playground.utils import extract_layer_params, extract_weight_tensors, compute_all_layer_ranges, get_layers_with_params"` succeeds
2. `ruff check playground/utils/parameter_inspector.py playground/quantization.py` passes
3. parameter_inspector.py contains functions for: single-layer param extraction, multi-model weight tensor extraction, whole-model range computation, and param-bearing layer identification
4. quantization.py dropdown cell uses dict-based options with "[Q]" markers
</verification>

<success_criteria>
- parameter_inspector.py exists with 4 functions, all importable
- Functions use onnx.numpy_helper.to_array (not hand-rolled parsing)
- Per-channel scales handled (ndim check)
- Dequantization formula applied correctly: (raw - zero_point) * scale
- Layer dropdown enhanced with "[Q]" indicators
- All existing notebook functionality preserved
- No lint errors
</success_criteria>

<output>
After completion, create `.planning/phases/15-parameter-inspection/15-01-SUMMARY.md`
</output>
