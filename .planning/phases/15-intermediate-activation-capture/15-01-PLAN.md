---
phase: 15-intermediate-activation-capture
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - playground/weight_visualizer.py
autonomous: true

must_haves:
  truths:
    - "User can select input source (CIFAR-10 sample by index or random input) via radio button in the notebook"
    - "User can trigger inference through the loaded PyTorch model and capture intermediate activations at all layers using forward hooks"
    - "User can select a layer and view activation histogram with statistics (shape, min, max, mean, std) in the same style as weight histograms"
    - "User can toggle between weight view and intermediate activation view for the same layer using radio buttons"
    - "Activation features are disabled (hidden or greyed out) when an ONNX model is selected, since forward hooks only work on nn.Module"
  artifacts:
    - path: "playground/weight_visualizer.py"
      provides: "Extended notebook with activation capture and visualization"
      contains: "run_with_hook"
  key_links:
    - from: "playground/weight_visualizer.py"
      to: "scripts/get_resnet8_intermediate.py"
      via: "import of load_cifar10_test_sample, normalize_input, run_with_hook, collect_named_tensors, get_model_layers"
      pattern: "from scripts\\.get_resnet8_intermediate import"
    - from: "input_source radio + index number"
      to: "activation capture cell"
      via: "radio.value determines CIFAR-10 vs random, index determines sample"
      pattern: "input_source.*value"
    - from: "view_toggle radio"
      to: "histogram rendering cell"
      via: "toggle value selects weight tensor_entry vs activation data for display"
      pattern: "view_toggle.*value"
---

<objective>
Add intermediate activation capture and visualization to the weight_visualizer notebook, enabling users to run inference through a PyTorch model and inspect activation distributions per layer.

Purpose: Users need to see what values flow through each layer during inference, not just the static weights. This helps debug model behavior, understand activation distributions, and compare how different inputs affect layer outputs.

Output: Extended `playground/weight_visualizer.py` with input source selection, activation capture via forward hooks, view toggle (weights vs activations), and activation histogram/stats reusing existing visualization patterns.
</objective>

<execution_context>
@/home/impactaky/shelffiles/config/claude/get-shit-done/workflows/execute-plan.md
@/home/impactaky/shelffiles/config/claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@playground/weight_visualizer.py
@scripts/get_resnet8_intermediate.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add input source selection and activation capture infrastructure</name>
  <files>playground/weight_visualizer.py</files>
  <action>
Extend the existing weight_visualizer.py notebook with new cells for input selection and activation capture. The wrapper pattern applies: import and call functions from `scripts/get_resnet8_intermediate.py` rather than reimplementing.

**Cell A: Import activation capture utilities (modify existing imports cell)**

In the first cell (imports), add `scripts/` to `sys.path` so the reference script functions are importable. Add this AFTER the existing `sys.path.insert(0, str(project_root))` line:

```python
scripts_dir = project_root / "scripts"
if str(scripts_dir) not in sys.path:
    sys.path.insert(0, str(scripts_dir))
```

Also import the functions needed from the reference script. Add after the sys.path setup:

```python
from get_resnet8_intermediate import (
    load_cifar10_test_sample,
    normalize_input,
    run_with_hook,
    collect_named_tensors,
    get_model_layers,
    load_model as load_intermediate_model,
)
```

Update the cell return to include these new imports.

**Cell B: Input source selection (new cell, after model loading cell)**

Create a new cell that shows input source selection UI. This cell should depend on `mo` and `model_data`. Only show when a PyTorch model is loaded (`model_data["format"] == "pytorch"`).

```python
@app.cell
def _(mo, model_data):
    """Input source selection for activation capture (PyTorch only)."""
    _is_pytorch = model_data.get("format") == "pytorch"

    input_source = mo.ui.radio(
        options={"CIFAR-10 sample": "cifar10", "Random input": "random"},
        value="CIFAR-10 sample",
        label="Input Source",
    )
    sample_index = mo.ui.number(
        start=0, stop=9999, step=1, value=0, label="Sample Index"
    )
    run_button = mo.ui.run_button(label="Run Inference")

    if _is_pytorch:
        mo.vstack([
            mo.md("### Intermediate Activations"),
            mo.hstack([input_source, sample_index, run_button], justify="start", gap=1),
        ])
    else:
        mo.md("_Activation capture requires a PyTorch model (.pt)_").callout(kind="neutral") if model_data.get("format") != "none" else None

    return input_source, run_button, sample_index
```

**Cell C: Activation capture (new cell, depends on model_selector, input_source, sample_index, run_button)**

This cell runs inference and captures activations at ALL layers when the run button is clicked. It reuses functions from the reference script.

Key implementation details:
- **DO NOT use `mo.stop()` for gating.** Use an if/else pattern so that `activation_data` and `activation_status` are ALWAYS defined (even as empty defaults). In Marimo, `mo.stop()` prevents the cell's return variables from being set, which would cause downstream cells referencing `activation_data` to error.
- Initialize `activation_data = {}` and `activation_status = ""` at the top of the cell
- Use `if not _is_pytorch or not run_button.value:` to skip capture (fall through to return defaults)
- In the else branch, perform the full capture logic
- Load the model using `load_intermediate_model(path, device)` from the reference script (NOT the existing `_load_pytorch_model` which returns a dict, not nn.Module)
- The device should be `torch.device("cpu")` (matching existing CPU-only approach in weight_visualizer)
- For CIFAR-10 input: call `load_cifar10_test_sample(data_dir, index)` with `data_dir` set to the default path `/mnt/ext1/references/tiny/benchmark/training/image_classification/cifar-10-batches-py`
- For random input: create `np.random.random((1, 32, 32, 3)).astype(np.float32)`
- Call `normalize_input(sample, device)` to convert to tensor
- Iterate over all layers from `get_model_layers(model)`, call `run_with_hook(model, layer_name, x)` for each, and `collect_named_tensors(value, layer_name)` to flatten
- Store results as a dict: `activation_data = {layer_name: {"values": arr.flatten().astype(np.float64), "shape": arr.shape} for layer_name, arr in all_named_tensors}`
- Handle errors gracefully: if CIFAR-10 data not found, show `mo.callout(kind="danger")` with message about missing data, suggest using random input
- Handle hook failures on individual layers gracefully (skip, don't crash)
- Use `mo.status.spinner(title="Capturing activations...")` around the capture loop
- The cell ALWAYS returns `activation_data` and `activation_status` (dict and string), even when capture was skipped

```python
@app.cell
def _(
    input_source,
    is_script_mode,
    model_data,
    model_selector,
    mo,
    np,
    run_button,
    sample_index,
):
    """Capture intermediate activations via forward hooks (PyTorch only)."""
    import torch

    # ALWAYS define defaults so downstream cells can reference activation_data
    activation_data = {}
    activation_status = ""
    _output = mo.md("")

    _is_pytorch = model_data.get("format") == "pytorch"
    if not _is_pytorch or not run_button.value:
        # Skip capture — return empty defaults
        pass
    else:
        _path = model_selector.value
        _device = torch.device("cpu")
        _data_dir = "/mnt/ext1/references/tiny/benchmark/training/image_classification/cifar-10-batches-py"

        with mo.status.spinner(title="Capturing activations..."):
            try:
                _model = load_intermediate_model(_path, _device)
                _model.eval()

                if input_source.value == "random":
                    _sample = np.random.random((1, 32, 32, 3)).astype(np.float32)
                    activation_status = "Input: random (1, 32, 32, 3)"
                else:
                    try:
                        _sample, _label = load_cifar10_test_sample(
                            _data_dir, int(sample_index.value)
                        )
                        activation_status = f"Input: CIFAR-10 test[{int(sample_index.value)}] (label={_label})"
                    except FileNotFoundError:
                        _output = mo.md(
                            "**CIFAR-10 data not found.** Use 'Random input' instead, "
                            f"or ensure data exists at `{_data_dir}`."
                        ).callout(kind="danger")
                        _output
                        return activation_data, activation_status

                _x = normalize_input(_sample, _device)
                _layers = get_model_layers(_model)

                for _ln in _layers:
                    try:
                        _value = run_with_hook(_model, _ln, _x)
                        _named = list(collect_named_tensors(_value, _ln))
                        for _tn, _arr in _named:
                            activation_data[_tn] = {
                                "values": _arr.flatten().astype(np.float64),
                                "shape": _arr.shape,
                            }
                    except Exception:
                        pass  # Skip layers where hooks fail

                _output = mo.md(
                    f"**Activations captured:** {len(activation_data)} tensors | {activation_status}"
                ).callout(kind="success")

            except Exception as _e:
                _output = mo.md(
                    f"**Activation capture failed:** {_e}"
                ).callout(kind="danger")

    _output
    return activation_data, activation_status
```

Important: The cell ALWAYS returns `activation_data` and `activation_status`, even when gating skips capture. This ensures downstream cells (view_toggle, display_entry resolver) never encounter undefined references.
  </action>
  <verify>
Run `marimo edit playground/weight_visualizer.py` (or `marimo run` in script mode). Verify:
1. Input source radio buttons appear when a .pt model is selected
2. Clicking "Run Inference" with "Random input" shows success callout with tensor count
3. When no model selected, activation UI is hidden
4. When ONNX model selected, shows "requires PyTorch" message
  </verify>
  <done>
Input source selection UI renders with radio (CIFAR-10/random), number input (sample index), and run button. Clicking run with random input captures activations from all layers and shows success message with count. CIFAR-10 mode works if data exists, shows helpful error if not. ONNX model shows informational message instead of activation controls.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add view toggle and activation histogram/stats display</name>
  <files>playground/weight_visualizer.py</files>
  <action>
Add a view toggle radio button and modify the histogram/stats cells to support showing either weight data or activation data based on the toggle selection.

**Cell D: View toggle (new cell, after layer/tensor selector area)**

Create a new cell with a radio button to switch between "Weights" and "Activations" views. This cell depends on `mo`, `model_data`, and `activation_data`. Only show the toggle when activation data has been captured.

```python
@app.cell
def _(activation_data, mo, model_data):
    """Toggle between weight and activation views."""
    _has_activations = bool(activation_data) if 'activation_data' in dir() else False
    _is_pytorch = model_data.get("format") == "pytorch"

    view_toggle = mo.ui.radio(
        options={"Weights": "weights", "Activations": "activations"},
        value="Weights",
        label="View",
    )
    view_toggle if _is_pytorch and _has_activations else None
    return (view_toggle,)
```

**Cell E: Resolve display data (new cell, central data routing)**

This cell selects the correct data to display based on the view toggle, layer selector, and tensor selector values. It produces a single `display_entry` dict that the histogram and stats cells consume.

```python
@app.cell
def _(activation_data, layer_selector, mo, model_data, tensor_entry, view_toggle):
    """Resolve which data to display based on view toggle."""
    activation_mismatch_msg = None
    if view_toggle.value == "activations" and activation_data:
        # Look for activation matching current layer
        _layer = layer_selector.value
        _act = activation_data.get(_layer)
        if _act is None:
            # Try prefix match (activation keys may have suffixes from collect_named_tensors)
            for _k, _v in activation_data.items():
                if _k.startswith(_layer + "_") or _k == _layer:
                    _act = _v
                    break
        if _act is None:
            activation_mismatch_msg = mo.md(
                f"**No activation captured for layer '{_layer}'.** "
                "Weight layer names and activation layer names may not align. "
                "Showing weight view instead."
            ).callout(kind="warn")
        display_entry = _act if _act is not None else tensor_entry
        display_mode = "activations" if _act is not None else "weights"
    else:
        display_entry = tensor_entry
        display_mode = "weights"
    activation_mismatch_msg
    return activation_mismatch_msg, display_entry, display_mode
```

Note: When activation data for the selected layer is not found (name mismatch between weight layers from state_dict and activation layers from named_modules), the cell shows a visible warning callout and falls back to weight view.

**Cell F: Update histogram cell to use display_entry**

Modify the EXISTING histogram cell (the one with `go.Histogram`) to use `display_entry` and `display_mode` instead of directly using `tensor_entry`. The cell signature changes from `_(bins_slider, go, mo, quant_view, tensor_entry)` to `_(bins_slider, display_entry, display_mode, go, mo, quant_view)`.

Key changes:
- Add `mo.stop(display_entry is None)` at the top
- For activation mode: always use `display_entry["values"]` (no quantization variants)
- For weight mode: keep existing quantization logic with `tensor_entry` replaced by `display_entry`
- Update title: "Weight Distribution" vs "Activation Distribution" based on `display_mode`
- Use `marker_color="steelblue"` for weights, `marker_color="darkorange"` for activations

Replace the existing histogram cell content with:

```python
@app.cell
def _(bins_slider, display_entry, display_mode, go, mo, quant_view):
    """Plotly histogram of weight or activation distribution."""
    mo.stop(display_entry is None)

    if display_mode == "activations":
        _data = display_entry["values"]
        _x_title = "Value"
        _title = "Activation Distribution"
        _color = "darkorange"
    else:
        _is_q = display_entry.get("is_quantized", False)
        if _is_q and quant_view.value == "int":
            _data = display_entry["int_values"]
            _x_title = "Value (int8/uint8)"
            _title = "Weight Distribution (Quantized Integer Values)"
        else:
            _data = display_entry["values"]
            _x_title = "Value"
            _title = "Weight Distribution"
        _color = "steelblue"

    _fig = go.Figure()
    _fig.add_trace(
        go.Histogram(
            x=_data,
            nbinsx=bins_slider.value,
            marker_color=_color,
            opacity=0.85,
            name="all",
            histnorm="percent",
            hovertemplate="Range: %{x}<br>Percent: %{y:.2f}%<extra></extra>",
        )
    )
    _fig.update_layout(
        title=_title,
        xaxis_title=_x_title,
        yaxis_title="Percentage (%)",
        bargap=0.05,
        height=450,
        template="plotly_white",
    )

    mo.ui.plotly(_fig)
    return
```

**Cell G: Update stats cell to use display_entry**

Modify the EXISTING statistics panel cell similarly. Change the cell signature from `_(mo, np, tensor_entry)` to `_(display_entry, display_mode, mo, np)`.

Replace the existing stats cell content with:

```python
@app.cell
def _(display_entry, display_mode, mo, np):
    """Statistics panel."""
    mo.stop(display_entry is None)

    _vals = display_entry["values"]
    _shape = display_entry["shape"]
    _min = float(np.min(_vals))
    _max = float(np.max(_vals))
    _mean = float(np.mean(_vals))
    _std = float(np.std(_vals))
    _total = int(np.prod(_shape))

    _mode_label = "Activation" if display_mode == "activations" else "Weight"
    _stats_lines = [
        f"**{_mode_label} Statistics**",
        f"**Min:** {_min:.6f} &nbsp;&nbsp; **Max:** {_max:.6f}",
        f"**Mean:** {_mean:.6f} &nbsp;&nbsp; **Std:** {_std:.6f}",
        f"**Shape:** {_shape} &nbsp;&nbsp; **Total elements:** {_total:,}",
    ]

    if display_mode == "weights" and display_entry.get("is_quantized", False):
        _scale = display_entry.get("scale")
        _zp = display_entry.get("zero_point")
        _scale_str = f"{_scale:.6f}" if _scale is not None else "N/A"
        _zp_str = f"{_zp:.1f}" if _zp is not None else "N/A"
        _stats_lines.append(
            f"**Scale:** {_scale_str} &nbsp;&nbsp; **Zero Point:** {_zp_str}"
        )

    mo.md("\n\n".join(_stats_lines)).callout(kind="neutral")
    return
```

**Cell H: Update value range analysis cells**

The two value range analysis cells (range inputs + highlighted histogram) also reference `tensor_entry` directly. Update them to use `display_entry` and `display_mode` in the same pattern. The range analysis cells should work for both weights and activations.

In the range inputs cell, change `tensor_entry` references to `display_entry` in the signature and body. In the highlighted histogram cell, change `tensor_entry` references to `display_entry`.

**Cell I: Update bins slider cell**

The bins slider cell checks `tensor_entry is not None` for visibility. Change this to `display_entry is not None`.

**Cell J: Update quantization view toggle cell**

The quantization view toggle should only appear when viewing weights (not activations). Add a condition: only show when `display_mode == "weights"` AND the entry is quantized.

**Marimo DAG considerations:**
- `activation_data` starts as empty dict `{}` when no inference has been run — cells referencing it must handle this (falsy check)
- The `display_entry` / `display_mode` cell acts as a router — downstream cells consume these instead of `tensor_entry` directly
- `view_toggle` defaults to "Weights" so existing weight visualization works unchanged when no activations captured
- Ensure no circular dependencies: the view_toggle cell reads `activation_data` but the activation capture cell does NOT read `view_toggle`
  </action>
  <verify>
Run `marimo edit playground/weight_visualizer.py`. Verify:
1. Load a .pt model, select a layer — weights histogram and stats show as before (regression check)
2. Click "Run Inference" with random input — activations captured
3. Toggle to "Activations" view — histogram changes to orange, title says "Activation Distribution"
4. Stats panel shows "Activation Statistics" with correct shape/min/max/mean/std
5. Toggle back to "Weights" — histogram returns to blue, stats show weight info
6. Quantization view toggle only appears in weight mode for quantized models
7. Value range analysis works in both modes
  </verify>
  <done>
View toggle radio button switches between "Weights" (blue histogram) and "Activations" (orange histogram) views. Both views show correct statistics. Histogram title, color, and stats label update based on mode. Quantization toggle is hidden in activation mode. Value range analysis works for both weights and activations. Existing weight visualization is fully preserved when no activations have been captured.
  </done>
</task>

<task type="auto">
  <name>Task 3: Handle downstream consumer edge cases and cell ordering</name>
  <files>playground/weight_visualizer.py</files>
  <action>
Handle edge cases in downstream consumer cells and verify correct cell ordering. Note: `activation_data` is always defined (Task 1's capture cell uses if/else, not mo.stop), so this task focuses on consumer behavior, NOT variable initialization.

**view_toggle cell: Handle empty activation_data**

The view_toggle cell (from Task 2) uses `_has_activations = bool(activation_data)`. Since `bool({}) == False`, this correctly hides the toggle when no activations have been captured. Verify this works and that the toggle only appears after a successful inference run.

**display_entry resolver: Handle None gracefully**

The display_entry resolver (from Task 2) already includes a mismatch fallback message. Additionally ensure:
- When `activation_data` is `{}` and toggle is "activations", `display_entry` should fall back to `tensor_entry` (not `None`)
- Downstream histogram/stats cells have `mo.stop(display_entry is None)` guards as safety nets

**Verify Marimo cell ordering:**

The notebook's cell order in the file doesn't matter for execution (DAG-driven), but DOES matter for visual layout. Ensure logical visual ordering:
1. Title
2. Model selection dropdown
3. Model loading
4. Input source selection + run button (NEW)
5. Activation capture (NEW)
6. Layer selector
7. Tensor type selector
8. View toggle (NEW)
9. Bins slider
10. Histogram
11. Value range analysis
12. Stats panel
13. Quantization toggle

The file's `@app.cell` order determines the visual top-to-bottom layout in the Marimo editor. Reorder cells if needed so activation-related cells appear in logical positions between model loading and layer selection.
  </action>
  <verify>
Run `marimo edit playground/weight_visualizer.py`. Test all states:
1. No model selected → no errors, no activation UI
2. ONNX model selected → "requires PyTorch" message, no crash
3. PyTorch model selected, no inference run → weight view works, view toggle hidden
4. Run inference with random input → activations captured, view toggle appears
5. Switch to activations view → activation histogram shown
6. Change layer in activation view → histogram updates for new layer (or shows mismatch warning if names differ)
7. Switch model to ONNX → activation data resets to empty, weight view only
8. Run `marimo run playground/weight_visualizer.py` in script mode → no crash
  </verify>
  <done>
Notebook handles all edge cases without errors. View toggle only appears after successful inference. display_entry resolver falls back gracefully on layer name mismatch with visible warning. Cell ordering in the file follows logical visual layout. Script mode works without crashes. All existing weight visualization functionality is preserved (no regressions).
  </done>
</task>

</tasks>

<verification>
1. `marimo run playground/weight_visualizer.py` completes without errors in script mode
2. In interactive mode with a .pt model:
   - Radio button for input source (CIFAR-10/random) is visible
   - "Run Inference" with random input shows success callout
   - View toggle switches between weight and activation histograms
   - Activation histogram is orange, weight histogram is blue
   - Stats panel shows correct shape/min/max/mean/std for both modes
3. In interactive mode with ONNX model: activation features hidden, weight visualization works
4. Layer selection updates both weight and activation data correctly
5. No circular dependency errors in Marimo DAG
</verification>

<success_criteria>
- All 4 requirements (INTM-01 through INTM-04) are implemented
- Input source selection with CIFAR-10 (by index) and random input works
- Forward hook activation capture produces tensors for all layers
- Activation histogram reuses existing Plotly histogram style (consistent UX)
- View toggle switches between weights and activations seamlessly
- No regressions to existing weight visualization functionality
- Graceful handling of missing CIFAR-10 data, ONNX models, and empty states
</success_criteria>

<output>
After completion, create `.planning/phases/15-intermediate-activation-capture/15-01-SUMMARY.md`
</output>
